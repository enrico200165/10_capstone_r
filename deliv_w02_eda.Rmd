---
title: "Explorative Data Analysis"
author: "Enrico V"
date: "April 2018"
output: html_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)
```


# Foreword  
In data science I have often heard statements like "start/lead with the question". Here I try to follow that principles.   
The question we are given in the capstone project is (next) word prediction.  
I have seen some didactic examples of EDA in NL where the "question"/goal was to predict whether an email was spam or not. For that and similar questions "neuter" and/or common words were considered not very useful, ex "stopwords" less common words could be useful and meaningful, so such analysis explore and use concepts like [TF-IDF](https://en.wikipedia.org/wiki/Tf-idf).  
At this very initial stages my understanding is that, due to the difference in the "question", at least in some cases, we have opposite requirement to the "predict spam" examples: for instance we are interested in very frequent words (and n-grams) so this analysis will be rather different from the spam examples.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```

```{r load_libraries, echo=FALSE}
require(quanteda)
require(readtext)
source("01_globals.R")
```



```{r load_files, echo=TRUE}
fnames_pattern <- file.path(data_dir_corpus,"*subset*")

blogs <- readtext(fnames_pattern
 ,docvarsfrom = "filenames", dvsep = "-"
 ,docvarnames = c("lang","title","subset","nlines_kept","nlines_read"))

myCorpus <- corpus(blogs)
print(summary(myCorpus))
```



